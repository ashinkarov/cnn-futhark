We thank the reviewers for their comments. Before responding to specific
questions below, we wish to explain the intent of our paper in a way that we
perhaps failed to do in the paper itself.

Our paper investigates the use of Agda as a practical tool for scientific
programming, covering the span from problem specification using rank
polymorphism, to transformation via AD, to optimisation and code generation. Not
all parts of the whole are equally completely specified: while rank polymorphism
is the most developed and fully verified part, the AD is performed within a
well-shaped and well-scoped DSL, verifying absence of bounds and scoping errors,
transformations that we run prior code generation guarantee semantics preservation
and code generation while implementing NBE does indeed use aptly termed
`String → String` monster.

In an ideal world, all parts would of course come with formal specifications
and accompanying proof, but in practice some parts remain an entirely separate
(and nontrivial) research effort to verify functionally correct (such as AD),
while others can be handled using known techniques (such as code generation),
but are somewhat time consuming. We wish to show that even in those cases where
resources preclude full verification, Agda can still be used as a practical
tool, with full verification employed where it is deemed desirable and
practical. This is what we mean by the somewhat oblique "correctness invariants
of our choice" in the abstract. Full verification of the entire pipeline is
naturally an important avenue for future work.

We agree that dependent types for index safety trace back to Xi and Pfenning,
and that our AD transformation is hardly state of the art, but our contribution
lies not just in reiterating these known ideas, but in engineering a practical
pipeline: from dependently-typed specifications in Agda to performant code
generation via Futhark, supporting non-trivial array programs and
transformations like AD.

## Answers to specific questions and remarks

### Reviewer A

> - How generally does your "unembedding" technique for HOAS-style wrappers of a deeply embedded DSL work? It works for your examples, but can you give any guarantees about the applicability of the technique? What are its limitations?

The key driver of the technique is the `Prefix` relation that checks whether
the context is a prefix of another and this is done automatically using 
the instance search.  This bit is solid, and for the DSLs with de Bruijn
variables, this works very well.  You'd have to define wrappers for all
the binders within your DSL, but this is straight-forward.

The limitation of all techniques that are based on instance search is
a bad complexity of instant search implementation.  When many things
turn into instances, instance search may have to traverse very large
search spaces (e.g. evaluating a large data structure of a constant
size, and so on).  However, this is not a problem related to DSL wrappers,
as we rarely define a very large number of local variables, we can
typically split a big expression into subexpressions and check them locally,
as we do with primitives in our CNN definition.

> - How does your "unembedding" technique relate to the technique from 
> Atkey, Robert, Sam Lindley, and Jeremy Yallop. "Unembedding domain-specific languages." Proceedings of the 2nd ACM SIGPLAN symposium on Haskell. 2009.

There is quite a significant difference, as this work
creates the actual data structure (`class Hoas`) that specifies construct
of the untyped language syntax.  Then untyped terms are scope- and type-checked
using instance resolution mechanism, and if all the instances match, they are
turned into unscoped de Bruijn, scoped de Bruijn, and simply-typed de Bruijn
representations.  Our technique never defines a particular HOAS syntax.
Every time we use our wrappers we conceptually write the term in `E`,
our wrappers simply help us to automate computation of well-typed
de Bruijn indices.  There is no conversion between representations
or type-checking of untyped terms.

> ? Is there any reason not to use this tried and tested technique?

The reason is that in `E` we have non-trivial dependencies in constructors.
Most of the constructors are polymorphic in array shapes, and proofs in `imapb`,
`selb`, etc depend on the shapes bound by the given constructor.  It is unclear
to me whether the proposed technique can easily handle such a case.  While this
might be the case, it does not look to very simple.  Once again, conceptually,
all our technique does, it automates computation of the offsets within the context.

> - What is the complexity of the code generated by your AD transformation? Does it really deserve to be called reverse AD?

I believe that this is deserved to be called reverse AD, as the algorithm computes
all the derivatives at the same time, sharing sub-expressions via introducing
local bindings on the way.  We never have to instantiate one derivative at a time
as in forward mode.

As for complexity, we implement a book-standard algorithm, yet instead of
using scalar elements, we use bulk operations on arrays.  As we represent
arrays as stateless functions, we rely on the optimisations to bring bulk
operations to the expected form.  Mainly, we aggressively fuse array updates
and we eliminate sums of `zero-but`s.  Furthermore, we rely on Futhark to take
care of lowering down a pretty high-level code into a chosen hardware efficiently.
With optimisations and Futhark code generation in place, we expect complexity
of the generated code to be $m$ times the complexity of the original function,
given that it takes $n$ arguments and returns $m$ arguments.

> - On l899 you say "direct compilation of the AD-generated expressions may be computationally inefficient". What are the main sources of inefficiency? Is there any way to classify them and address them systematically? Are your optimizations guaranteed to fix the problems on any other programs than your one example.

As mentioned above there are two sources of inefficiency: excessive copying and
`zero-but` representation.  Excessive copying is a known problem in array languages,
and there seem to be no universal solution found so far.  However, the proposed
heuristics (e.g. fusion is controlled by inserting let bindings) gives good practical
results.  As for `zero-but` we could introduce a special operator that updates
array at a certain index.  However, we found that that the current approach has
a certain beauty, as it is based just on array combinators and nothing else.
We did test our optimisations on multiple smaller examples, and we observed
that generated expressions are of the same shape as human-written ones.  In
fact the code generated for our CNN example is very much similar to the one
that we wrote by hands first.  We do not have a formal proof that optimisations
fix all the problems, but as our language is very small, the number of patterns
that we had to consider is relatively small as well.

> - Do you have any reason to believe that your code transformation computes derivatives other than evaluation on your one example?

Yes, as all our differentiation rules are specified in about 20 lines of code
(lines 979-830) it is relatively easy to convince yourself that they are doing
the right thing.  Most of these rules are book-standard differentiation rules
like `(f + g)' = f' + g'`.  The only non-trivial rule is the chain rule, and its
non-triviality has to do with: (i) our well-scoped encoding, and (ii) the fact that
we are sharing derivative of the let binding with its potential uses avoiding
inlining.  Now, ideally we would like to demonstrate that our ∇ is the actually a
linear approximation (derivative).  For this we'd have to introduce a lot of scaffolding
such as real numbers, deltas, jacobians, etc.  With those we'd have to define
correctness criteria for ∇, and it seems that specification of let case is likely
to be as complex as the implementation within ∇.  By no means we are disputing
that this should not be done, we just point out that it is likely that the correctness
specification might be still not convince the reader due to potential complexity.


### Reviewer B

### Reviewer C

#### Improving the benchmarks

The JIT behaviour of industry-standard machine learning tools do pose challenges
for benchmarking, *particularly* when the MNIST benchmark is by modern standards
rather small, so the setup time becomes dominant. This is why we have isolated
it in our measurements. Alternatively, we could inflate the number of training
epochs to inflate the training time, although this is unlikely to actually
improve the training result, and so feels artificial. The purpose of our
experiment is not to provide comprehensive evidence for outperforming
TensorFlow, but to show that the performance of our system seems sufficient to
be useful.

#### Correctness of translation to Futhark

There are no correctness guarantees in the present work, largely for practical
reasons. Since Futhark's dynamic semantics are quite straightforward and similar
to those of Agda, verification is possible via known techniques, but requires
somewhat tedious modelling Futhark in Agda.  All the compilation to Futhark
takes 50 lines of very straight-forward code, so the chances of making a mistake,
given that the generated code is accepted by the compiler are sufficiently small.
On the other hand, correctness of transformations within the DSL is much more
tedious, as we perform non-trivial rewrites, and we managed to catch a few
incorrect ones due to inability to construct a proof.

### Reviewer D

#### On the artifact

The artifact is indeed not in a portable state, as we did not anticipate
reviewers would desire to run it at this stage in the process (but are certainly
pleasantly surprised!). The reason is that due to the somewhat complex
dependencies (GPUs, Python library infrastructure), Docker is the most
accessible way to package it, but the GPU-equipped system on which we did our
work does not support Docker. This will of course be rectified in case the paper
is accepted.
